{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497b7a31-a2d2-4ddb-8e99-bc08b7d2f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dspy\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a79c68f-551d-4bb8-a421-2fd5c146c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5194a39e-d66f-4793-b705-3f00a1d11153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "187a3212-329a-4e6d-a9d4-e2d43c940f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #generate llm object\n",
    "# local_config = {\n",
    "#     \"api_base\": \"http://localhost:11434/v1\",  # 注意需加/v1路徑\n",
    "#     \"api_key\": \"NULL\",  # 特殊標記用於跳過驗證\n",
    "#     \"model\": \"deepseek-r1:7b\",\n",
    "#     \"custom_llm_provider\":\"deepseek\"\n",
    "# }\n",
    "\n",
    "# dspy.configure(\n",
    "#     lm=dspy.LM(\n",
    "#         **local_config\n",
    "#     )\n",
    "# )\n",
    "# # 測試問答\n",
    "# qa = dspy.Predict('question -> answer')\n",
    "# response = qa(question=\"中國唐朝有幾任皇帝?\")\n",
    "# print(f\"模型回答：{response.answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1588eef-a7c5-4d96-8ec4-291c390feb18",
   "metadata": {},
   "source": [
    "### ref: https://dspy.ai/tutorials/rag/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acb39963-03b4-4671-bd73-4de3f568f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitializeLLM():\n",
    "    local_config = {\n",
    "        \"api_base\": \"http://localhost:11434/v1\",  # 注意需加/v1路徑\n",
    "        \"api_key\": \"NULL\",  # 特殊標記用於跳過驗證\n",
    "        \"model\": \"deepseek-r1:7b\",\n",
    "        \"custom_llm_provider\":\"deepseek\"\n",
    "    }\n",
    "    dspy.configure(\n",
    "        lm=dspy.LM(\n",
    "            **local_config\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1cb72-8185-497e-8a1d-7c124bfdea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InitializeLLM();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfdceb93-ca65-4a46-9ead-be92e9d5ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_predict(queryStr:str=None):\n",
    "    if queryStr == None:\n",
    "        raise ValueError(\"query string is none, please input query string.\")\n",
    "    promptPatternStr = \"question -> answer\"\n",
    "    qa = dspy.Predict(promptPatternStr);\n",
    "    response = qa(question=queryStr);\n",
    "    print(f\"llm:{response.answer}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca617257-df47-4b54-b0a4-78e9e65e4bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm:October 26th\n"
     ]
    }
   ],
   "source": [
    "llm_predict(\"what day is today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d61cc9fa-9f6d-421b-bce0-e4d720fbf23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-02-21T16:17:14.651093]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `answer` (str)\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "what day is today\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## answer ## ]]\n",
      "October 26th\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c80803a-54e6-4738-8092-db1f79435c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='{The reasoning field is where you would provide a detailed thought process or explanation based on the input question. It should be structured in a way that clearly shows how you arrived at your answer.}',\n",
       "    response='{The response field is where you provide a concise and direct answer to the question, typically one or two sentences long. It should be clear and to the point, summarizing the key points from your reasoning.}'\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot = dspy.ChainOfThought('question -> response')\n",
    "cot(question=\"should curly braces appear on their own line?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc710b0a-d387-4d62-a975-f8d04c485675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./data/ragqa_arena_tech_examples.jsonl\") as f:\n",
    "#     data = [ujson.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb6053-ae91-4c26-8e51-f5b13950c7d6",
   "metadata": {},
   "source": [
    "### Basic RAG\n",
    "- dspy.Embedder: https://dspy.ai/api/models/Embedder/\n",
    "- multihop Search: https://dspy.ai/tutorials/multihop_search/?h=search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa443466-0f70-4946-a899-84ca853a3629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28436 documents. Will encode them below.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd479d12f274c01ac70c15d6285ccc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/141 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56a865f07bd4364a5c06d5186288fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/226 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d2fc9c29d1492f831baab7799fa2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/670k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc3dfd0e467475db643c8c5fbdcd238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_StaticEmbedding%2Ftokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43fcee5cd7b432cadabd84596238ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/125M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a 32-byte FAISS index with 337 partitions, based on 28436 x 1024-dim embeddings\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_characters = 6000  # for truncating >99th percentile of documents\n",
    "topk_docs_to_retrieve = 5  # number of documents to retrieve per search query\n",
    "\n",
    "with open(\"../data/ragqa_arena_tech_corpus.jsonl\") as f:\n",
    "    corpus = [ujson.loads(line)['text'][:max_characters] for line in f]\n",
    "    print(f\"Loaded {len(corpus)} documents. Will encode them below.\")\n",
    "model = SentenceTransformer(\"sentence-transformers/static-retrieval-mrl-en-v1\", device=\"cpu\")\n",
    "embedder = dspy.Embedder(model=model.encode, dimensions=512)\n",
    "search = dspy.retrievers.Embeddings(embedder=embedder, corpus=corpus, k=topk_docs_to_retrieve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af952782-3d44-4a60-8157-5550b1fdd15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can use StartSound.PrefPane which basically just sets the volume to 0 when you shutdown and then turns it back up after login.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d4ed7ae-2576-4533-a0f5-12996c8be92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.respond=dspy.ChainOfThought('context, question -> answer');\n",
    "\n",
    "    def forward(self,question):\n",
    "        context = search(question).passages\n",
    "        return self.respond(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4b10937-7bfc-41df-8888-e8e8a1964e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning='High Memory on Linux is typically used by user-space applications and is separate from Low Memory, which is reserved for the kernel. This separation prevents application interference and ensures efficient resource management.',\n",
      "    answer='High Memory refers to the physical memory allocated for user-space applications, while Low Memory is reserved for the kernel. This distinction helps prevent application-kernel interference and optimizes performance by keeping hardware resources accessible only to the kernel when needed.'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rag = RAG();\n",
    "print(rag(question=\"what are high memory and low memory on linux?\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "225ae1f3-71b6-4287-a472-6d73d5bf75cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-02-21T17:15:25.940977]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `context` (str)\n",
      "2. `question` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `answer` (str)\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## context ## ]]\n",
      "{context}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `context`, `question`, produce the fields `answer`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[1] «Reading system memory usage in Activity Monitor from support.apple.com gives a detailed explanation about the different types of RAM. Free memory: This is RAM thats not being used. Wired memory: Information in this memory cant be moved to the hard disk, so it must stay in RAM. The amount of Wired memory depends on the applications you are using. Active memory: This information is currently in memory, and has been recently used. Inactive memory: This information in memory is not actively being used, but was recently used. Used: This is the total amount of memory used.»\n",
      "[2] «You ideally want both banks the same, this will allow interleaving which almost doubles the memory access speed. In computing, interleaved memory is a design made to compensate for the relatively slow speed of dynamic random-access memory (DRAM) or core memory, by spreading memory addresses evenly across memory banks. That way, contiguous memory reads and writes are using each memory bank in turn, resulting in higher memory throughputs due to reduced waiting for memory banks to become ready for desired operations. Source : http://en.wikipedia.org/wiki/Interleaved_memory»\n",
      "[3] «Real mem relates to physical memory (actual RAM modules in your computer). Virtual Mem is how much fake memory is allocated to the process, meaning memory that is allocated on the permanent storage medium (hard drive, solid state drive, etc) for that process. Shared memory is physical (Real) memory that can be shared with other processes. Private memory is real memory that can only be used by the process it is allocated to. These explanations may help as well... directly from activity monitor --> help --> viewing system memory usage: Here is an explanation of some of the information displayed at the bottom of the memory pane: Wired: Wired memory contains information that must always stay in RAM Active: Active memory that contains information that is actively being used. Inactive: Inactive memory contains information that is not actively being used. Leaving this information in RAM is to your advantage if you (or a client of your computer) come back to it later. Used: Used memory is being used by a process or by the system. Used memory is the sum of wired, active, and inactive memory. If the system requires memory it takes free memory before used memory. Free: Free memory is not being used and is immediately available. VM size: Virtual memory, or VM, is hard disk space that can be used as memory. VM size is the amount of disk space being used as memory. Mac OS X can use more memory than the amount of physical RAM you have. A hard disk is much slower than RAM, so the virtual memory system automatically distributes information between disk space and RAM for efficient performance. Page ins/outs: The number of gigabytes of information Mac OS X has moved between RAM and disk space»\n",
      "[4] «As far as I remember, High Memory is used for application space and Low Memory for the kernel. Advantage is that (user-space) applications cant access kernel-space memory.»\n",
      "[5] «Theres a key difference between managing memory as a resource (when you dont care whats inside and shouldnt even look), and using memory to do something else (when the contents are the whole point). ... memory administration is often better accomplished ... The quote is talking about managing memory addressing and maps, where youre treating memory as some opaque resource to be managed. The code you posted isnt managing memory as a resource, its using some memory to do non-memory-management-related stuff (specifically DMA to an audio device).»\n",
      "\n",
      "[[ ## question ## ]]\n",
      "what are high memory and low memory on linux?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32mHigh Memory refers to the portion of physical memory allocated for user-space applications, ensuring they don't interfere with the kernel's operations. Low Memory is reserved for the kernel itself, which needs direct access to hardware resources for efficient performance.\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "High Memory on Linux is typically used by user-space applications and is separate from Low Memory, which is reserved for the kernel. This separation prevents application interference and ensures efficient resource management.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "High Memory refers to the physical memory allocated for user-space applications, while Low Memory is reserved for the kernel. This distinction helps prevent application-kernel interference and optimizes performance by keeping hardware resources accessible only to the kernel when needed.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449b6d1-86ca-4885-a01d-de8b36cb28a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
