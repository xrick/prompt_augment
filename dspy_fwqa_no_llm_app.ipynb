{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc683aa6-8190-4d72-978f-6aaffadfad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import faiss\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.vectorstores import FAISS as LangchainFAISS\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5eb4cf-2c75-4f39-85ae-fd2b0c524fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0557d3af-ebb9-4eb2-9be1-5c11369d2ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dspy-ai transformers torch faiss-cpu sentence-transformers langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe4687d7-1179-4730-bd5d-ffc39d2a898a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "錯誤: The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Custom Retriever for DSPy that uses your existing FAISS setup\n",
    "class CustomFAISSRetriever(dspy.Retrieve):\n",
    "    def load_index(idx_path=None):\n",
    "    #載入預訓練的FAISS索引\n",
    "        try:\n",
    "            index = faiss.read_index(self, idx_path)\n",
    "            print(f\"成功載入FAISS索引，包含 {index.ntotal} 個向量\")\n",
    "            return index\n",
    "        except Exception as e:\n",
    "            print(f\"索引載入失敗: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def load_local_db(self, local_db_path=None):\n",
    "        #載入完整的向量資料庫\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "        )\n",
    "        try:\n",
    "            db = FAISS.load_local(\n",
    "                folder_path=local_db_path,\n",
    "                embeddings=embeddings,\n",
    "                allow_dangerous_deserialization=True  # 必要安全參數\n",
    "            )\n",
    "            print(f\"載入成功，共 {db.index.ntotal} 筆技術問答\")\n",
    "            return db\n",
    "        except Exception as e:\n",
    "            print(f\"向量庫載入異常: {str(e)}\")\n",
    "            return None\n",
    "            \n",
    "    def __init__(self, faiss_index_path, vector_db_path, k=3):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        # Load the FAISS index\n",
    "        self.index = faiss.read_index(faiss_index_path)\n",
    "        # Load the vector store\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "        )\n",
    "        self.vector_db = LangchainFAISS.load_local(\n",
    "            vector_db_path,\n",
    "            self.embeddings\n",
    "        )\n",
    "        # Initialize the sentence transformer\n",
    "        self.model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "    \n",
    "    def __call__(self, query):\n",
    "        # Encode the query\n",
    "        query_embedding = self.model.encode(\n",
    "            query,\n",
    "            convert_to_tensor=False,\n",
    "            show_progress_bar=False\n",
    "        )\n",
    "        \n",
    "        # Search in vector DB\n",
    "        docs = self.vector_db.similarity_search_with_score(query, k=self.k)\n",
    "        \n",
    "        # Format results\n",
    "        passages = []\n",
    "        for doc, score in docs:\n",
    "            context = doc.page_content\n",
    "            metadata = doc.metadata\n",
    "            formatted_context = f\"{context}\\nSource: {metadata['source']}\\nLast Updated: {metadata['last_updated']}\"\n",
    "            passages.append(formatted_context)\n",
    "        \n",
    "        return dspy.Prediction(passages=passages)\n",
    "\n",
    "# 2. Setup DSPy with custom retriever\n",
    "def setup_retriever(faiss_index_path, vector_db_path):\n",
    "    retriever = CustomFAISSRetriever(faiss_index_path, vector_db_path)\n",
    "    return retriever\n",
    "\n",
    "# 3. Simple search function\n",
    "def search_similar_questions(retriever, question):\n",
    "    results = retriever(question)\n",
    "    return results.passages\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Initialize retriever\n",
    "        retriever = setup_retriever(\n",
    "            faiss_index_path=\"./db/qa_index.faiss\",\n",
    "            vector_db_path=\"./db/tech_support_faiss\"\n",
    "        )\n",
    "        \n",
    "        # Test question\n",
    "        question = \"請問如何處理系統異常?\"\n",
    "        results = search_similar_questions(retriever, question)\n",
    "        \n",
    "        print(f\"問題: {question}\")\n",
    "        print(\"\\n相關文件:\")\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n--- 文件 {i} ---\")\n",
    "            print(result)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"錯誤: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976826d5-23d5-4bb9-9efd-429853cec009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
